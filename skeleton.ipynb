{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skeleton.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ehi1150I7fxN",
        "outputId": "dfefb569-7046-4500-a867-8fd0cde4244a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42GqAEWKJt7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "link_hilstrom = 'https://drive.google.com/open?id=15osyN4c5z1pSo1JkxwL_N8bZTksRvQuU'\n",
        "fluff, id = link_hilstrom.split('=')\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Hillstrom.csv')\n",
        "hillstrom_df = pd.read_csv('Hillstrom.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7tAS92JMPe9U",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "link_ = 'https://drive.google.com/open?id=1b8N7WtwIe2WmQJD1KL5UAy70K13MxwKj'\n",
        "fluff, id = link_.split('=')\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Lalonde.csv')\n",
        "lalonde_df = pd.read_csv('Lalonde.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVl-Kuj3Jxv7",
        "colab_type": "code",
        "outputId": "01d84dca-47cf-4ab3-9b86-5d6b496d575f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "print(hillstrom_df[:5])\n",
        "print(lalonde_df[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   recency history_segment  history  ...  visit  conversion spend\n",
            "0       10  2) $100 - $200   142.44  ...      0           0   0.0\n",
            "1        6  3) $200 - $350   329.08  ...      0           0   0.0\n",
            "2        7  2) $100 - $200   180.65  ...      0           0   0.0\n",
            "3        9  5) $500 - $750   675.83  ...      0           0   0.0\n",
            "4        2    1) $0 - $100    45.34  ...      0           0   0.0\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "   treatment   age  education  black  ...  married  nodegree  RE75        RE78\n",
            "0        1.0  37.0       11.0    1.0  ...      1.0       1.0   0.0   9930.0460\n",
            "1        1.0  22.0        9.0    0.0  ...      0.0       1.0   0.0   3595.8940\n",
            "2        1.0  30.0       12.0    1.0  ...      0.0       0.0   0.0  24909.4500\n",
            "3        1.0  27.0       11.0    1.0  ...      0.0       1.0   0.0   7506.1460\n",
            "4        1.0  33.0        8.0    1.0  ...      0.0       1.0   0.0    289.7899\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZoNrZI5P80wJ",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "\n",
        "def preprocess_data(df, dataset='hillstrom', verbose=True):\n",
        "    \"\"\"\n",
        "    Preprocessing the dataset\n",
        "     - Use one-hot encoding for categorical features\n",
        "     - Check the name of the target variable and treatment variable\n",
        "     - Drop the unused columns\n",
        "     - Delete the unused data\n",
        "    \n",
        "    Args:\n",
        "        df: A pandas.DataFrame which have all data of the dataset\n",
        "        dataset: the name of the dataset\n",
        "    Return:\n",
        "        # I recommend to split into the dataframes of predictor variables, the \n",
        "        # target variable, and the treatment varaible\n",
        "        # df_x: the dataframes of predictor variables\n",
        "        # df_y: target variables\n",
        "        # df_t: treatment variables\n",
        "    \"\"\"\n",
        "    if dataset in ['hillstrom', 'email']:\n",
        "        # For Hillstrom dataset, the ‘‘visit’’ target variable was selected\n",
        "        #   as the target variable of interest and the selected treatment is \n",
        "        #   the e-mail campaign for women’s merchandise [1]\n",
        "        # [1] Kane K, Lo VSY, Zheng J. True-lift modeling: Comparison of methods. \n",
        "        #    J Market Anal. 2014;2:218–238\n",
        "    \n",
        "        # Delete unused data: men's email cases should be removed\n",
        "        df_x = df[df.segment != 'Mens E-Mail']\n",
        "        \n",
        "        # Assign Y for target (visit: 0, 1)\n",
        "        df_y = df_x['visit']\n",
        "        \n",
        "        # Assign T for treatment (segment: Womens E-Mail, Mens E-Mail (not used), No E-Mail)\n",
        "        df_t = (df_x['segment'] == 'Womens E-Mail').astype('int64')\n",
        "\n",
        "        # Drop unused columns from X\n",
        "        df_x = df_x.drop(columns=['conversion', 'spend', 'visit', 'segment'])\n",
        "        \n",
        "        # One-hot encoding for categorical features\n",
        "        df_x = pd.get_dummies(df_x)\n",
        "\n",
        "    elif dataset in ['criteo', 'ad']:\n",
        "        raise NotImplementedError\n",
        "    elif dataset in ['lalonde', 'job']:\n",
        "        # Delete unused data: None\n",
        "        df_x = df\n",
        "\n",
        "        # Target variables (RE78: earnings in 1978)\n",
        "        df_y = df_x['RE78']\n",
        "        \n",
        "        # Treatment variables (treatment: 0, 1)\n",
        "        df_t = df_x['treatment']\n",
        "\n",
        "        # Drop unused columns\n",
        "        df_x = df_x.drop(columns=['treatment', 'RE78'])\n",
        "        \n",
        "        # One-hot encoding for categorical features\n",
        "        df_x = pd.get_dummies(df_x)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return df_x, df_y, df_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNeOLP5CKWDJ",
        "colab_type": "code",
        "outputId": "6e873ea9-f489-41b1-e931-16e551af93f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "def print_preproccessing_data(df_x, df_y, df_t):\n",
        "    print(df_x[:5])\n",
        "    print(df_x.columns.values)\n",
        "    print(df_x.shape)\n",
        "    print(df_y[:5])\n",
        "    print(df_t[:5])\n",
        "\n",
        "\n",
        "hillstrom_df_x, hillstrom_df_y, hillstrom_df_t = preprocess_data(hillstrom_df, 'hillstrom')\n",
        "print_preproccessing_data(hillstrom_df_x, hillstrom_df_y, hillstrom_df_t)\n",
        "\n",
        "lalonde_df_x, lalonde_df_y, lalonde_df_t = preprocess_data(lalonde_df, 'lalonde')\n",
        "print_preproccessing_data(lalonde_df_x, lalonde_df_y, lalonde_df_t)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   recency  history  mens  ...  channel_Multichannel  channel_Phone  channel_Web\n",
            "0       10   142.44     1  ...                     0              1            0\n",
            "1        6   329.08     1  ...                     0              0            1\n",
            "2        7   180.65     0  ...                     0              0            1\n",
            "4        2    45.34     1  ...                     0              0            1\n",
            "5        6   134.83     0  ...                     0              1            0\n",
            "\n",
            "[5 rows x 18 columns]\n",
            "['recency' 'history' 'mens' 'womens' 'newbie'\n",
            " 'history_segment_1) $0 - $100' 'history_segment_2) $100 - $200'\n",
            " 'history_segment_3) $200 - $350' 'history_segment_4) $350 - $500'\n",
            " 'history_segment_5) $500 - $750' 'history_segment_6) $750 - $1,000'\n",
            " 'history_segment_7) $1,000 +' 'zip_code_Rural' 'zip_code_Surburban'\n",
            " 'zip_code_Urban' 'channel_Multichannel' 'channel_Phone' 'channel_Web']\n",
            "(42693, 18)\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "4    0\n",
            "5    1\n",
            "Name: visit, dtype: int64\n",
            "0    1\n",
            "1    0\n",
            "2    1\n",
            "4    1\n",
            "5    1\n",
            "Name: segment, dtype: int64\n",
            "    age  education  black  hispanic  married  nodegree  RE75\n",
            "0  37.0       11.0    1.0       0.0      1.0       1.0   0.0\n",
            "1  22.0        9.0    0.0       1.0      0.0       1.0   0.0\n",
            "2  30.0       12.0    1.0       0.0      0.0       0.0   0.0\n",
            "3  27.0       11.0    1.0       0.0      0.0       1.0   0.0\n",
            "4  33.0        8.0    1.0       0.0      0.0       1.0   0.0\n",
            "['age' 'education' 'black' 'hispanic' 'married' 'nodegree' 'RE75']\n",
            "(722, 7)\n",
            "0     9930.0460\n",
            "1     3595.8940\n",
            "2    24909.4500\n",
            "3     7506.1460\n",
            "4      289.7899\n",
            "Name: RE78, dtype: float64\n",
            "0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "Name: treatment, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Igf3QLgdJ1cW",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def performance(pr_y1_ct1, pr_y1_ct0, y, ct, groups=10):\n",
        "    \"\"\"\n",
        "    1. Split the total customers into the given number of groups\n",
        "    2. Calculate the statistics of each segment\n",
        "    \n",
        "    Args:\n",
        "        pr_y1_ct1: the series (list) of the customer's expected return\n",
        "        pr_y1_ct0: the expected return when a customer is not treated\n",
        "        y: the observed return of customers\n",
        "        ct: whther each customer is treated or not\n",
        "        groups: the number of groups (segments). Should be 5, 10, or 20\n",
        "    Return:\n",
        "        DataFrame:\n",
        "            columns:\n",
        "                'n_y1_ct1': the number of treated responders\n",
        "                'n_y1_ct0': the number of not treated responders\n",
        "                'r_y1_ct1': the average return of treated customers\n",
        "                'r_y1_ct0': the average return of not treated customers\n",
        "                'n_ct1': the number of treated customers\n",
        "                'n_ct0': the number of not treated customers\n",
        "                'uplift': the average uplift (the average treatment effect)\n",
        "            rows: the index of groups\n",
        "    \"\"\"\n",
        "\n",
        "    ### check valid arguments\n",
        "    if groups not in [5, 10, 20]:\n",
        "        raise Exception(\"uplift: groups must be either 5, 10 or 20\")\n",
        "\n",
        "    ### check for NAs.\n",
        "    if pr_y1_ct1.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in pr_y1_ct1\")\n",
        "    if pr_y1_ct0.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in pr_y1_ct0\")\n",
        "    if y.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in y\")\n",
        "    if ct.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in ct\")\n",
        "\n",
        "    ### check valid values for ct\n",
        "    if set(ct) != {0, 1}:\n",
        "        raise Exception(\"uplift: ct must be either 0 or 1\")\n",
        "\n",
        "    ### check length of arguments\n",
        "    if not (len(pr_y1_ct1) == len(pr_y1_ct0) == len(y) == len(ct)):\n",
        "        raise Exception(\"uplift: arguments pr_y1_ct1, pr_y1_ct0, y and ct must all have the same length\")\n",
        "\n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    # Make group id to split\n",
        "    group_id = (pd.Series(range(0, len(ct))) / (len(ct) / groups)).astype('int32').set_index(ct.index)\n",
        "    \n",
        "    # Split input data frame by group id\n",
        "    # tr: treated responder\n",
        "    # cr: controlled responder\n",
        "    df = pd.DataFrame(data={'tr': y & ct, 'cr': y & (ct == 0), 'ct': ct,\n",
        "                            'exp_tr': pr_y1_ct1 & ct, 'exp_cr': pr_y1_ct0 & ct, 'group_id': group_id})\n",
        "    print(df)\n",
        "    df_group = df.groupby('group_id')\n",
        "    \n",
        "    # Get group data\n",
        "    n_ct1 = df['ct'].aggregate('sum')\n",
        "    n_ct0 = (df['ct'] == 0).aggregate('sum')\n",
        "\n",
        "    n_y1_ct1 = df['tr'].aggregate('sum')\n",
        "    print(df['tr'])\n",
        "    print(n_y1_ct1)\n",
        "    n_y1_ct0 = df['cr'].aggregate('sum')\n",
        "    print(df['cr'])\n",
        "    print(n_y1_ct0)\n",
        "    \n",
        "    r_y1_ct1 = df['tr'].aggregate('mean')\n",
        "    print(r_y1_ct1)\n",
        "    \n",
        "    r_y1_ct0 = df['cr'].aggregate('mean')\n",
        "    \n",
        "    uplift = r_y1_ct1 - r_y1_ct0\n",
        "    \n",
        "    # Create output data frame by grouped input data frame\n",
        "    return pd.DataFrame(data={'n_y1_ct1': n_y1_ct1, 'n_y1_ct0': n_y1_ct0, 'r_y1_ct1': r_y1_ct1, 'r_y1_ct0': r_y1_ct0,\n",
        "                              'n_ct1': n_ct1, 'n_ct0': n_ct0, 'uplift': uplift})\n",
        "\n",
        "\n",
        "def qini(perf, plotit=True):\n",
        "    \"\"\"\n",
        "    Calculating the incremental gains (y-axis of Qini curve)\n",
        "     - First, the cumulitative sum of the treated and the control groups are\n",
        "      calculated with respect to the total population in each group at the\n",
        "      specified decile\n",
        "     - Afterwards we calculate the percentage of the total amount of people\n",
        "      (both treatment and control) are present in each decile\n",
        "    Args:\n",
        "        perf: A return of the performance function (above)\n",
        "        plotit: whether draw a plot or not\n",
        "    Return:\n",
        "        1. Qini value\n",
        "        2. return or save the plot if plotit is True\n",
        "    \"\"\"\n",
        "    \n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    return ##\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sxbN8mbRX0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b81ab93a-957b-4948-a00f-63a2b8314df3"
      },
      "source": [
        "df = performance(hillstrom_df_y, hillstrom_df_y, hillstrom_df_y, hillstrom_df_t, 10)\n",
        "print(df)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-23c375904cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhillstrom_df_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhillstrom_df_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhillstrom_df_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhillstrom_df_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-569c8ef338b8>\u001b[0m in \u001b[0;36mperformance\u001b[0;34m(pr_y1_ct1, pr_y1_ct0, y, ct, groups)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m###############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Make group id to split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mgroup_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Split input data frame by group id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'set_index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrxjl1v7J9Mm",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def parameter_tuning(fit_mdl, pred_mdl, data, search_space):\n",
        "    \"\"\"\n",
        "    Given a model, search all combination of parameter sets and find\n",
        "    the best parameter set\n",
        "    \n",
        "    Args:\n",
        "        fit_mdl: model function\n",
        "        pred_mdl: predict function of fit_mdl\n",
        "        data:\n",
        "            {\n",
        "                \"x_train\": predictor variables of training dataset,\n",
        "                \"y_train\": target variables of training dataset,\n",
        "                \"ct_train\": treatment variables of training dataset,\n",
        "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
        "                \"y_test\": target variables of test (usually, validation) dataset,\n",
        "                \"ct_test\": treatment variables of test (usually, validation) dataset,\n",
        "            }\n",
        "        search_space:\n",
        "            {\n",
        "                parameter_name: [search values]\n",
        "            }\n",
        "    Return:\n",
        "        The best parameter set\n",
        "    \"\"\"\n",
        "    \n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    return ##\n",
        "\n",
        "  \n",
        "def wrapper(fit_mdl, pred_mdl, data)\n",
        "    \"\"\"\n",
        "    General wrapper approach\n",
        "    \n",
        "    Args:\n",
        "        fit_mdl: model function\n",
        "        pred_mdl: predict function of fit_mdl\n",
        "        data:\n",
        "            {\n",
        "                \"x_train\": predictor variables of training dataset,\n",
        "                \"y_train\": target variables of training dataset,\n",
        "                \"ct_train\": treatment variables of training dataset,\n",
        "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
        "                \"y_test\": target variables of test (usually, validation) dataset,\n",
        "                \"ct_test\": treatment variables of test (usually, validation) dataset,\n",
        "            }\n",
        "    Return:\n",
        "        (A list of best models, The list of dropped variables)\n",
        "    \"\"\"\n",
        "    \n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    return ##\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CxrEbEODlbQi",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "def tma(x, y, ct, method=LogisticRegression, **kwargs):\n",
        "    \"\"\"Training a model according to the \"Two Model Approach\" \n",
        "    (a.k.a. \"Separate Model Approach\")\n",
        "    The default model is General Linear Model (GLM)\n",
        "    \n",
        "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
        "\n",
        "    Args:\n",
        "        x: A data frame of predictors.\n",
        "        y: A binary response (numeric) vector.\n",
        "        ct: A binary response (numeric) representing the treatment assignment\n",
        "            (coded as 0/1).\n",
        "        method: A sklearn model specifying which classification or regression\n",
        "            model to use. This should be a method that can handle a \n",
        "            multinominal class variable.\n",
        "\n",
        "    Return:\n",
        "        Dictionary: A dictionary of two models. One for the treatment group, \n",
        "            one for the control group.\n",
        "\n",
        "            {\n",
        "                'model_treat': a model for the treatment group,\n",
        "                'model_control': a model for the control group\n",
        "            }\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    return {\n",
        "        'model_treat': method(random_state=1234, solver='newton-cg').fit(x[ct == 1], y[ct == 1]),\n",
        "        'model_control': method(random_state=1234, solver='newton-cg').fit(x[ct == 0], y[ct == 0])\n",
        "    }\n",
        "\n",
        "\n",
        "def predict_tma(obj, newdata, **kwargs):\n",
        "    \"\"\"Predictions according to the \"Two Model Approach\" \n",
        "    (a.k.a. \"Separate Model Approach\")\n",
        "    \n",
        "    For each instance in newdata two predictions are made:\n",
        "    1) What is the probability of a person responding when treated?\n",
        "    2) What is the probability of a person responding when not treated\n",
        "      (i.e. part of control group)?\n",
        "\n",
        "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
        "\n",
        "    Args:\n",
        "        obj: A dictionary of two models. \n",
        "            One for the treatment group, one for the control group.\n",
        "        newdata: A data frame containing the values at which predictions\n",
        "            are required.\n",
        "    \n",
        "    Return:\n",
        "        DataFrame: A dataframe with predicted returns for when the customers\n",
        "            are treated and for when they are not treated.\n",
        "    \"\"\"\n",
        "\n",
        "    ###############################\n",
        "    ###     Do it yourself!     ###\n",
        "    ###############################\n",
        "    df_x = newdata.drop(['X', 'Y'])\n",
        "    s_y = newdata['Y']\n",
        "    s_t = newdata['T']\n",
        "    \n",
        "    return obj['model_treat'](df_x, s_y, s_t) - obj['model_control'](df_x, s_y, s_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hREl_CRv9DYC",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 1234\n",
        "\n",
        "def main():\n",
        "    ### Load data ###\n",
        "    hillstrom_df_pre = preprocess_data(hillstrom_df, 'hillstrom')\n",
        "    # lalonde_df_pre = preprocess_data(lalonde_df, 'lalonde')\n",
        "    \n",
        "    print(hillstrom_df_pre)\n",
        "    data_train, data_test = train_test_split(hillstrom_df_pre)\n",
        "    print(data_train)\n",
        "    print(data_test)\n",
        "    assert()\n",
        "    \n",
        "    for model in models:\n",
        "        ### Cross validation ###\n",
        "        x_train, y_train, x_test, y_test = train_test_split(hillstrom_df_pre)\n",
        "        \n",
        "        ### Variable selection (General wrapper approach) ###\n",
        "\n",
        "        ### Parameter tuning ###\n",
        "\n",
        "        print(\"Model: {}\\n\".format(model))\n",
        "        print(\"Tuning space: \\n\")\n",
        "        for key, val in search_space.items():\n",
        "            print(\"    '{}': {}\\n\".format(key, val))\n",
        "        print(\"Seed: {}\\n\".format(seed))\n",
        "        print(\"Qini value: mean = {}, std = {}\\n\\n\".format(mean_qini, std_qini))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9X42GUaj-UX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c651339-bf1f-4868-ea4d-c108d6303cd9"
      },
      "source": [
        "main()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       recency  history  mens  womens  ...  channel_Phone  channel_Web  Y      T\n",
            "0           10   142.44     1       0  ...              1            0  0   True\n",
            "1            6   329.08     1       1  ...              0            1  0  False\n",
            "2            7   180.65     0       1  ...              0            1  0   True\n",
            "4            2    45.34     1       0  ...              0            1  0   True\n",
            "5            6   134.83     0       1  ...              1            0  1   True\n",
            "6            9   280.20     1       0  ...              1            0  0   True\n",
            "7            9    46.42     0       1  ...              1            0  0   True\n",
            "9           10    32.84     0       1  ...              0            1  0   True\n",
            "10           7   548.91     0       1  ...              1            0  1   True\n",
            "11           1   211.45     0       1  ...              1            0  0   True\n",
            "12           5   642.90     0       1  ...              0            0  0   True\n",
            "14           4   241.42     0       1  ...              0            0  0  False\n",
            "15           3    58.13     1       0  ...              0            1  1  False\n",
            "20           9    29.99     0       1  ...              1            0  0  False\n",
            "23           2    29.99     0       1  ...              1            0  0  False\n",
            "24           4    78.24     1       0  ...              0            1  0  False\n",
            "28           7   435.73     0       1  ...              0            1  0  False\n",
            "29           2   203.35     1       0  ...              0            1  0  False\n",
            "30           2   237.53     0       1  ...              1            0  0   True\n",
            "34           3    29.99     1       0  ...              0            1  0   True\n",
            "35           4   218.72     0       1  ...              0            0  0   True\n",
            "38          10    63.79     1       0  ...              1            0  0   True\n",
            "42           9   204.18     0       1  ...              0            1  0   True\n",
            "43           2   492.02     1       0  ...              1            0  0  False\n",
            "44           1    48.32     0       1  ...              0            1  0  False\n",
            "45          10    29.99     1       0  ...              1            0  0  False\n",
            "46           2   391.33     1       0  ...              0            1  0  False\n",
            "48           3   134.59     1       0  ...              1            0  1   True\n",
            "49          10    61.09     0       1  ...              0            1  0   True\n",
            "50           3   203.30     0       1  ...              0            1  0  False\n",
            "...        ...      ...   ...     ...  ...            ...          ... ..    ...\n",
            "63953        5   166.24     0       1  ...              1            0  0  False\n",
            "63954        2    93.97     1       0  ...              0            1  1  False\n",
            "63956        9   341.24     1       0  ...              1            0  0  False\n",
            "63957       10   433.36     1       1  ...              0            0  0  False\n",
            "63958        7    65.82     1       0  ...              1            0  0   True\n",
            "63960        1   221.89     0       1  ...              0            0  0  False\n",
            "63962       10   144.59     1       0  ...              1            0  0   True\n",
            "63965        8    58.58     0       1  ...              1            0  0  False\n",
            "63966        4   170.03     1       0  ...              0            1  0   True\n",
            "63967        5    77.73     0       1  ...              1            0  0  False\n",
            "63969        3    67.78     0       1  ...              0            1  0   True\n",
            "63970        4   191.15     0       1  ...              0            1  0   True\n",
            "63971        5   549.87     0       1  ...              1            0  0   True\n",
            "63972        3   554.97     0       1  ...              0            1  0  False\n",
            "63973        8   471.80     1       0  ...              0            0  0   True\n",
            "63975       10   883.92     1       0  ...              1            0  0  False\n",
            "63976        1   710.72     1       1  ...              1            0  0  False\n",
            "63977        8    29.99     0       1  ...              0            1  1  False\n",
            "63979       10   168.21     0       1  ...              1            0  0  False\n",
            "63980        3   487.10     0       1  ...              1            0  0  False\n",
            "63981        4   125.53     0       1  ...              1            0  0  False\n",
            "63983        2    83.03     0       1  ...              1            0  0  False\n",
            "63984        2   209.51     0       1  ...              0            1  0   True\n",
            "63986        9    35.26     0       1  ...              0            1  0   True\n",
            "63987        1    79.70     1       0  ...              0            1  0  False\n",
            "63989       10   304.30     1       1  ...              0            1  1   True\n",
            "63990        6    80.02     0       1  ...              1            0  0  False\n",
            "63991        1   306.10     1       0  ...              1            0  0   True\n",
            "63993        4   374.07     0       1  ...              1            0  0   True\n",
            "63998        1   552.94     1       0  ...              0            0  0   True\n",
            "\n",
            "[42693 rows x 20 columns]\n",
            "       recency  history  mens  womens  ...  channel_Phone  channel_Web  Y      T\n",
            "25568        6   160.76     0       1  ...              0            1  0  False\n",
            "29870        2    29.99     0       1  ...              0            1  0  False\n",
            "32144        7    68.09     1       0  ...              1            0  0  False\n",
            "33610       10   134.82     0       1  ...              0            1  0  False\n",
            "41975        4   180.93     0       1  ...              0            1  0  False\n",
            "34955       10   163.69     0       1  ...              1            0  0   True\n",
            "44048        8   219.04     1       0  ...              0            0  0   True\n",
            "44441       11    29.99     1       0  ...              1            0  0  False\n",
            "685          2   227.46     1       0  ...              0            1  0  False\n",
            "34442        2    32.34     0       1  ...              1            0  1  False\n",
            "12746        2   952.61     1       1  ...              0            0  0  False\n",
            "33890        1    43.22     1       0  ...              0            1  0  False\n",
            "27222        2   245.50     0       1  ...              1            0  0   True\n",
            "17771        9    62.50     0       1  ...              1            0  0  False\n",
            "17723       10   606.57     1       0  ...              0            0  1  False\n",
            "22483       10   135.94     0       1  ...              0            1  0  False\n",
            "9011        10   400.87     1       0  ...              1            0  0   True\n",
            "24475        3   269.96     0       1  ...              0            1  0   True\n",
            "34669        3   250.76     0       1  ...              0            1  0  False\n",
            "213          8   138.62     0       1  ...              0            1  0   True\n",
            "14616        8    29.99     1       0  ...              1            0  0   True\n",
            "19824        2   499.92     0       1  ...              1            0  1   True\n",
            "44869        5   436.32     1       0  ...              1            0  1  False\n",
            "1168        10    29.99     0       1  ...              0            1  0  False\n",
            "54401       10   134.72     0       1  ...              0            1  0  False\n",
            "18195        9   101.45     1       0  ...              0            1  1  False\n",
            "2909        10    50.46     0       1  ...              1            0  1   True\n",
            "14999        2   162.12     1       0  ...              0            1  0  False\n",
            "12176       11    35.06     0       1  ...              1            0  0  False\n",
            "43335        8    64.94     1       0  ...              0            1  0   True\n",
            "...        ...      ...   ...     ...  ...            ...          ... ..    ...\n",
            "41425        6    31.37     0       1  ...              0            1  0  False\n",
            "46154        8   185.20     0       1  ...              1            0  0   True\n",
            "53138        4    86.91     0       1  ...              1            0  1  False\n",
            "33142        5   326.60     1       0  ...              0            0  0  False\n",
            "53172       12    29.99     0       1  ...              0            1  0  False\n",
            "12530        2   239.00     1       0  ...              1            0  0   True\n",
            "31353        4    43.29     1       0  ...              1            0  0  False\n",
            "54554        6   575.13     0       1  ...              0            0  0  False\n",
            "42773        6   177.56     1       0  ...              1            0  0   True\n",
            "14829        2   101.10     1       0  ...              0            1  0  False\n",
            "59792        1   213.64     1       0  ...              1            0  0  False\n",
            "15222        1   223.54     1       1  ...              1            0  0   True\n",
            "10986       10    34.97     1       0  ...              0            1  0  False\n",
            "51851        2   186.53     0       1  ...              1            0  0  False\n",
            "33464        5   180.69     1       0  ...              1            0  1   True\n",
            "60677        3    38.24     0       1  ...              0            1  0   True\n",
            "60129       10   203.22     1       0  ...              1            0  1   True\n",
            "6300         1    81.26     0       1  ...              1            0  0   True\n",
            "22320        5   243.98     0       1  ...              0            1  0  False\n",
            "63942        3    29.99     1       0  ...              1            0  0  False\n",
            "13819        3   148.08     0       1  ...              1            0  0   True\n",
            "58393        2   452.26     0       1  ...              1            0  0  False\n",
            "53397        5    95.69     1       0  ...              0            1  1  False\n",
            "47902        4   117.28     1       0  ...              1            0  0  False\n",
            "49999        2  1025.03     1       1  ...              0            1  0  False\n",
            "63414        2    93.85     1       0  ...              1            0  0  False\n",
            "54953        5   117.27     0       1  ...              1            0  0   True\n",
            "57851        3   660.02     1       1  ...              0            1  0  False\n",
            "7589         1    52.01     1       0  ...              0            1  1   True\n",
            "49690        3   283.78     0       1  ...              0            1  0   True\n",
            "\n",
            "[32019 rows x 20 columns]\n",
            "       recency  history  mens  womens  ...  channel_Phone  channel_Web  Y      T\n",
            "32698        2    56.03     0       1  ...              1            0  0  False\n",
            "20096        1   528.79     1       1  ...              1            0  0  False\n",
            "25670        9   188.20     1       0  ...              0            1  0   True\n",
            "45995        2   208.18     0       1  ...              0            0  0  False\n",
            "24347        6    71.99     0       1  ...              1            0  0  False\n",
            "60744       11    99.84     0       1  ...              1            0  0  False\n",
            "40625       12   103.41     1       0  ...              0            1  0  False\n",
            "63457        2  1002.07     0       1  ...              1            0  0  False\n",
            "63317        9    90.35     0       1  ...              0            1  0  False\n",
            "24054        1   110.91     1       0  ...              0            1  0   True\n",
            "10096        8   711.21     1       1  ...              0            0  0   True\n",
            "6478         6    46.71     1       0  ...              1            0  0  False\n",
            "29993       10    58.44     1       0  ...              0            1  0   True\n",
            "15166        5    97.32     0       1  ...              0            1  0  False\n",
            "3380         3  1676.60     1       0  ...              0            0  1  False\n",
            "44212        3   141.37     0       1  ...              0            1  0  False\n",
            "48507        3    61.23     0       1  ...              1            0  0   True\n",
            "54416       12   490.24     1       0  ...              1            0  1   True\n",
            "19807       10    29.99     1       0  ...              1            0  0  False\n",
            "4629         8    73.73     1       0  ...              1            0  0   True\n",
            "4047         2   352.68     0       1  ...              1            0  0  False\n",
            "10118        1   354.59     1       0  ...              1            0  0   True\n",
            "44654        3   193.99     0       1  ...              1            0  1  False\n",
            "54559        6   547.25     1       0  ...              1            0  0  False\n",
            "22439        3   116.66     1       0  ...              1            0  0  False\n",
            "13541        2    54.17     1       0  ...              0            1  0   True\n",
            "38357        2   585.72     1       0  ...              0            0  1  False\n",
            "11702       10   295.64     0       1  ...              1            0  0  False\n",
            "12603        2   232.97     0       1  ...              0            1  0   True\n",
            "44514        8   286.11     0       1  ...              0            0  0  False\n",
            "...        ...      ...   ...     ...  ...            ...          ... ..    ...\n",
            "39978        4    29.99     1       0  ...              1            0  0  False\n",
            "30249        1   341.56     1       0  ...              1            0  0   True\n",
            "58771       11   100.84     1       0  ...              1            0  0  False\n",
            "36648       12   415.01     0       1  ...              0            1  0   True\n",
            "15023        2    62.96     0       1  ...              0            1  0   True\n",
            "19536        3   351.59     0       1  ...              0            0  0  False\n",
            "16460        7   185.50     0       1  ...              0            1  0  False\n",
            "62205        4   102.71     0       1  ...              0            1  0  False\n",
            "6699         1   719.93     0       1  ...              1            0  0  False\n",
            "5941         3    29.99     1       0  ...              1            0  0  False\n",
            "20035        2   102.65     0       1  ...              0            1  1   True\n",
            "34799        4    50.84     0       1  ...              1            0  0  False\n",
            "41215        4   317.41     1       0  ...              1            0  0   True\n",
            "54170       10   208.29     1       1  ...              0            1  1  False\n",
            "43447        8    29.99     0       1  ...              0            1  0   True\n",
            "19640        9   211.32     0       1  ...              1            0  0  False\n",
            "45653        1   147.37     1       0  ...              0            1  0   True\n",
            "60297       10   265.68     0       1  ...              0            1  0   True\n",
            "36316        3    67.75     0       1  ...              0            1  0   True\n",
            "21394       12   106.99     1       0  ...              0            1  0  False\n",
            "61533        2   264.59     0       1  ...              0            1  1   True\n",
            "58134        9   415.43     0       1  ...              0            1  0  False\n",
            "56035       10    55.02     1       0  ...              1            0  0  False\n",
            "40944        7    44.99     1       0  ...              1            0  0   True\n",
            "43347        9   108.63     1       0  ...              1            0  0   True\n",
            "7590        10    29.99     1       0  ...              0            1  0   True\n",
            "45728        5    70.22     1       0  ...              1            0  0   True\n",
            "7512         8   357.95     1       0  ...              0            1  0  False\n",
            "59157       11   128.13     0       1  ...              0            1  0  False\n",
            "52742       10   214.74     1       1  ...              0            0  0   True\n",
            "\n",
            "[10674 rows x 20 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-de68af0b2bcf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}