{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skeleton.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ehi1150I7fxN",
        "outputId": "70858652-c7db-42f0-c51b-ac3bc9bcfb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42GqAEWKJt7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "link_hilstrom = 'https://drive.google.com/open?id=15osyN4c5z1pSo1JkxwL_N8bZTksRvQuU'\n",
        "fluff, id = link_hilstrom.split('=')\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Hillstrom.csv')\n",
        "hillstrom_df = pd.read_csv('Hillstrom.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7tAS92JMPe9U",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "link_ = 'https://drive.google.com/open?id=1b8N7WtwIe2WmQJD1KL5UAy70K13MxwKj'\n",
        "fluff, id = link_.split('=')\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Lalonde.csv')\n",
        "lalonde_df = pd.read_csv('Lalonde.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZoNrZI5P80wJ",
        "colab": {}
      },
      "source": [
        "def preprocess_data(df, dataset='hillstrom', verbose=True):\n",
        "    \"\"\"\n",
        "    Preprocessing the dataset\n",
        "     - Use one-hot encoding for categorical features\n",
        "     - Check the name of the target variable and treatment variable\n",
        "     - Drop the unused columns\n",
        "     - Delete the unused data\n",
        "    Args:\n",
        "        df: A pandas.DataFrame which have all data of the dataset\n",
        "        dataset: the name of the dataset\n",
        "    Return:\n",
        "        # I recommend to split into the data frames of predictor variables,\n",
        "        # the target variable, and the treatment variable\n",
        "        # df: the data frames of predictor variables\n",
        "        # df['T']: target variables\n",
        "        # df['Y']: treatment variables\n",
        "    \"\"\"\n",
        "    if dataset in ['hillstrom', 'email']:\n",
        "        # For Hillstrom dataset, the ‘‘visit’’ target variable was selected\n",
        "        #   as the target variable of interest and the selected treatment is\n",
        "        #   the e-mail campaign for women’s merchandise [1]\n",
        "        # [1] Kane K, Lo VSY, Zheng J. True-lift modeling: Comparison of methods.\n",
        "        #    J Market Anal. 2014;2:218–238\n",
        "\n",
        "        # Delete unused data: men's email cases should be removed\n",
        "        df = df[df.segment != 'Mens E-Mail'].reset_index()\n",
        "        # Assign Y for target (visit: 0, 1)\n",
        "        df['Y'] = df['visit']\n",
        "        # Assign T for treatment (segment: Womens E-Mail, Mens E-Mail (not used), No E-Mail)\n",
        "        df['T'] = (df['segment'] == 'Womens E-Mail').astype('int64')\n",
        "        # Drop unused columns from X\n",
        "        df = df.drop(columns=['conversion', 'spend', 'visit', 'segment', 'index'])\n",
        "        # One-hot encoding for categorical features\n",
        "        df = pd.get_dummies(df)\n",
        "\n",
        "    elif dataset in ['criteo', 'ad']:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    elif dataset in ['lalonde', 'job']:\n",
        "        # Delete unused data: None\n",
        "        df = df.reset_index()\n",
        "        # Target variables (RE78: earnings in 1978)\n",
        "        df['Y'] = df['RE78']\n",
        "        # Treatment variables (treatment: 0, 1)\n",
        "        df['T'] = df['treatment']\n",
        "        # Drop unused columns\n",
        "        df = df.drop(columns=['treatment', 'RE78', 'index'])\n",
        "        # One-hot encoding for categorical features\n",
        "        df = pd.get_dummies(df)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Igf3QLgdJ1cW",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def performance(pr_y1_t1, pr_y1_t0, y, t, groups=10):\n",
        "    \"\"\"\n",
        "    1. Split the total customers into the given number of groups\n",
        "    2. Calculate the statistics of each segment\n",
        "    Args:\n",
        "        pr_y1_t1: the series (list) of the customer's expected return\n",
        "        pr_y1_t0: the expected return when a customer is not treated\n",
        "        y: the observed return of customers\n",
        "        t: whether each customer is treated or not\n",
        "        groups: the number of groups (segments). Should be 5, 10, or 20\n",
        "    Return:\n",
        "        DataFrame:\n",
        "            columns:\n",
        "                'n_y1_t1': the number of treated responders\n",
        "                'n_y1_t0': the number of not treated responders\n",
        "                'r_y1_t1': the average return of treated customers\n",
        "                'r_y1_t0': the average return of not treated customers\n",
        "                'n_t1': the number of treated customers\n",
        "                'n_t0': the number of not treated customers\n",
        "                'uplift': the average uplift (the average treatment effect)\n",
        "            rows: the index of groups\n",
        "    \"\"\"\n",
        "\n",
        "    ### check valid arguments\n",
        "    if groups not in [5, 10, 20]:\n",
        "        raise Exception(\"uplift: groups must be either 5, 10 or 20\")\n",
        "\n",
        "    ### check for NAs.\n",
        "    if pr_y1_t1.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in pr_y1_t1\")\n",
        "    if pr_y1_t0.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in pr_y1_t0\")\n",
        "    if y.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in y\")\n",
        "    if t.isnull().values.any():\n",
        "        raise Exception(\"uplift: NA not permitted in t\")\n",
        "\n",
        "    ### check valid values for ct\n",
        "    if set(t) != {0, 1}:\n",
        "        raise Exception(\"uplift: t must be either 0 or 1\")\n",
        "\n",
        "    ### check length of arguments\n",
        "    if not (len(pr_y1_t1) == len(pr_y1_t0) == len(y) == len(t)):\n",
        "        raise Exception(\"uplift: arguments pr_y1_t1, pr_y1_t0, y and t must all have the same length\")\n",
        "\n",
        "    # TR(y1_t1): treated responder, CR(y1_t0): controlled responder\n",
        "    # Uplift = P(TR) - P(CR)\n",
        "    # Customers ordered by predicted uplift values in descending order are segmented.\n",
        "    df = pd.DataFrame(data={'t': t, 'y': y,\n",
        "                            'uplift_rank': (pr_y1_t1 - pr_y1_t0).rank(ascending=False, method='first')})\n",
        "    df_group = df.groupby(pd.qcut(df['uplift_rank'], groups, labels=range(1, groups + 1)).rename('group'))\n",
        "    \n",
        "    # Get group data\n",
        "    n_t1 = df_group['t'].sum()\n",
        "    n_t0 = df_group['t'].count() - n_t1\n",
        "    n_y1_t1 = df_group.apply(lambda r: r[r['t'] == 1]['y'].sum())\n",
        "    n_y1_t0 = df_group.apply(lambda r: r[r['t'] == 0]['y'].sum())\n",
        "    r_y1_t1 = n_y1_t1 / n_t1\n",
        "    r_y1_t0 = n_y1_t0 / n_t0\n",
        "    uplift = r_y1_t1 - r_y1_t0\n",
        "\n",
        "    return pd.DataFrame(data={'n_y1_t1': n_y1_t1, 'n_y1_t0': n_y1_t0,\n",
        "                              'r_y1_t1': r_y1_t1, 'r_y1_t0': r_y1_t0,\n",
        "                              'n_t1': n_t1, 'n_t0': n_t0, 'uplift': uplift})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQWYAcXZEyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def plot_qini_curve(x, y_list):\n",
        "    \"\"\"\n",
        "    Plot qini curve with multiple Y\n",
        "    \"\"\"\n",
        "    for y in y_list:\n",
        "        plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def calc_auuc(decile_width, decile_size, gains):\n",
        "    \"\"\"\n",
        "    Calculate AUUC (Area Under Uplift Curve) and return AUUC value and list\n",
        "    \"\"\"\n",
        "    auuc = 0\n",
        "    auuc_list = [auuc]\n",
        "    for i in range(1, decile_size + 1):\n",
        "        auuc += 0.5 * decile_width * (gains[i] + gains[i - 1])\n",
        "        auuc_list.append(auuc)\n",
        "    return auuc, auuc_list\n",
        "\n",
        "\n",
        "def qini(perf, plotit=True):\n",
        "    \"\"\"\n",
        "    Calculating the incremental gains (y-axis of Qini curve)\n",
        "     - First, the cumulative sum of the treated and the control groups are\n",
        "      calculated with respect to the total population in each group at the\n",
        "      specified decile\n",
        "     - Afterwards we calculate the percentage of the total amount of people\n",
        "      (both treatment and control) are present in each decile\n",
        "    Args:\n",
        "        perf: A return of the performance function (above)\n",
        "        plotit: whether draw a plot or not\n",
        "    Return:\n",
        "        1. Qini value\n",
        "        2. return or save the plot if plotit is True\n",
        "    \"\"\"\n",
        "    n_size = len(perf)\n",
        "    cumsum_r_y1_t1 = perf['n_y1_t1'].cumsum() / perf['n_t1'].cumsum()\n",
        "    cumsum_r_y1_t0 = perf['n_y1_t0'].cumsum() / perf['n_t0'].cumsum()\n",
        "    deciles = np.linspace(0, 1, num=n_size + 1)\n",
        "    decile_width = 1 / n_size\n",
        "\n",
        "    # Model Incremental gains: first gain is 0\n",
        "    inc_gains = ([0] + list(cumsum_r_y1_t1 - cumsum_r_y1_t0)) * deciles\n",
        "\n",
        "    # Overall incremental gains\n",
        "    overall_inc_gain = perf['n_y1_t1'].sum() / perf['n_t1'].sum() - perf['n_y1_t0'].sum() / perf['n_t0'].sum()\n",
        "\n",
        "    # Random incremental gains\n",
        "    random_inc_gains = overall_inc_gain * deciles\n",
        "\n",
        "    # Compute area under the model incremental gains (uplift) curve\n",
        "    auuc, auuc_list = calc_auuc(decile_width, n_size, inc_gains)\n",
        "\n",
        "    # Compute area under the random incremental gains curve\n",
        "    auuc_rand, auuc_rand_list = calc_auuc(decile_width, n_size, random_inc_gains)\n",
        "\n",
        "    # Compute the difference between the areas (Qini coefficient)\n",
        "    qini_coefficient = auuc - auuc_rand\n",
        "\n",
        "    # Qini 30%, Qini 10%\n",
        "    n_30p = int(n_size * 0.3)\n",
        "    n_10p = int(n_size * 0.1)\n",
        "    qini_30p = auuc_list[n_30p] - auuc_rand_list[n_30p]\n",
        "    qini_10p = auuc_list[n_10p] - auuc_rand_list[n_10p]\n",
        "\n",
        "    # Plot incremental gains curve\n",
        "    if plotit:\n",
        "        plot_qini_curve(deciles, [inc_gains, random_inc_gains])\n",
        "\n",
        "    return {\n",
        "        'qini': qini_coefficient,\n",
        "        'inc_gains': inc_gains,\n",
        "        'random_inc_gains': random_inc_gains,\n",
        "        'auuc_list': auuc_list,\n",
        "        'auuc_rand_list': auuc_rand_list,\n",
        "        'qini_30p': qini_30p,\n",
        "        'qini_10p': qini_10p,\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrxjl1v7J9Mm",
        "colab": {}
      },
      "source": [
        "def parameter_tuning(fit_mdl, pred_mdl, data, search_space):\n",
        "    \"\"\"\n",
        "    Given a model, search all combination of parameter sets and find\n",
        "    the best parameter set\n",
        "    Args:\n",
        "        fit_mdl: model function\n",
        "        pred_mdl: predict function of fit_mdl\n",
        "        data:\n",
        "            {\n",
        "                \"x_train\": predictor variables of training dataset,\n",
        "                \"y_train\": target variables of training dataset,\n",
        "                \"t_train\": treatment variables of training dataset,\n",
        "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
        "                \"y_test\": target variables of test (usually, validation) dataset,\n",
        "                \"t_test\": treatment variables of test (usually, validation) dataset,\n",
        "            }\n",
        "        search_space:\n",
        "            {\n",
        "                parameter_name: [search values]\n",
        "            }\n",
        "    Return:\n",
        "        The best parameter set\n",
        "    \"\"\"\n",
        "    max_q = -float('inf')\n",
        "    best_mdl = None\n",
        "\n",
        "    # Grid search: find all possible cases\n",
        "    keys = search_space.keys()\n",
        "    n_space = [len(search_space[key]) for key in keys]\n",
        "    n_iter = np.prod(n_space)\n",
        "\n",
        "    best_params = None\n",
        "    for i in range(n_iter):\n",
        "        # Make grid search params\n",
        "        params = {}\n",
        "        for idx, key in enumerate(keys):\n",
        "            params[key] = search_space[key][i % n_space[idx]]\n",
        "            i = int(i / n_space[idx])\n",
        "\n",
        "        # Build model and predict\n",
        "        mdl = fit_mdl(data['x_train'], data['y_train'], data['t_train'], **params)\n",
        "        pred = pred_mdl(mdl, newdata=data['x_test'], y=data['y_test'], ct=data['t_test'])\n",
        "\n",
        "        # Calculate qini value\n",
        "        try:\n",
        "            perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], data['y_test'], data['t_test'])\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "\n",
        "        q = qini(perf, plotit=False)['qini']\n",
        "        if q > max_q:\n",
        "            max_q = q\n",
        "            best_mdl = mdl\n",
        "            best_params = params\n",
        "\n",
        "    return best_mdl, best_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTA6Q3pwZodM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrapper(fit_mdl, pred_mdl, data, params=None,\n",
        "            best_models=None, drop_variables=None, qini_values=None):\n",
        "    \"\"\"\n",
        "    General wrapper approach\n",
        "    Args:\n",
        "        fit_mdl: model function\n",
        "        pred_mdl: predict function of fit_mdl\n",
        "        data:\n",
        "            {\n",
        "                \"x_train\": predictor variables of training dataset,\n",
        "                \"y_train\": target variables of training dataset,\n",
        "                \"t_train\": treatment variables of training dataset,\n",
        "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
        "                \"y_test\": target variables of test (usually, validation) dataset,\n",
        "                \"t_test\": treatment variables of test (usually, validation) dataset,\n",
        "            }\n",
        "        params: given parameters for model\n",
        "        best_models:\n",
        "        drop_variables: don't check performance for those variables\n",
        "        qini_values:\n",
        "    Return:\n",
        "        (A list of best models, The list of dropped variables)\n",
        "    \"\"\"\n",
        "    if best_models is None:\n",
        "        best_models = []\n",
        "    if drop_variables is None:\n",
        "        drop_variables = []\n",
        "    if qini_values is None:\n",
        "        qini_values = []\n",
        "    if params is None:\n",
        "        params = {}\n",
        "\n",
        "    max_q = -float('inf')\n",
        "    drop_var = None\n",
        "    best_mdl = None\n",
        "\n",
        "    # Check performance drop for each predictor variable\n",
        "    variables = data['x_train'].columns\n",
        "    for var in variables:\n",
        "        if var in drop_variables:\n",
        "            continue\n",
        "\n",
        "        # Build and train model\n",
        "        x = data['x_train'].drop(drop_variables + [var], axis=1)\n",
        "        mdl = fit_mdl(x, data['y_train'], data['t_train'], **params)\n",
        "\n",
        "        # Predict by the model\n",
        "        x = data['x_test'].drop(drop_variables + [var], axis=1)\n",
        "        pred = pred_mdl(mdl, newdata=x, y=data['y_test'], t=data['t_test'])\n",
        "\n",
        "        # Calculate qini value\n",
        "        perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], data['y_test'], data['t_test'])\n",
        "        q = qini(perf, plotit=False)['qini']\n",
        "        if q > max_q:\n",
        "            max_q = q\n",
        "            drop_var = var\n",
        "            best_mdl = mdl\n",
        "\n",
        "    best_models.append(best_mdl)\n",
        "    drop_variables.append(drop_var)\n",
        "    qini_values.append(max_q)\n",
        "\n",
        "    if len(variables) == len(drop_variables) + 1:\n",
        "        left_vars = [var for var in variables if var not in drop_variables]\n",
        "        return best_models, drop_variables + left_vars, qini_values\n",
        "    else:\n",
        "        return wrapper(fit_mdl, pred_mdl, data, params=params,\n",
        "                       best_models=best_models, drop_variables=drop_variables,\n",
        "                       qini_values=qini_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CxrEbEODlbQi",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "\n",
        "\n",
        "def tma(x, y, t, method=LogisticRegression, **kwargs):\n",
        "    \"\"\"Training a model according to the \"Two Model Approach\"\n",
        "    (a.k.a. \"Separate Model Approach\")\n",
        "    The default model is General Linear Model (GLM)\n",
        "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
        "    Args:\n",
        "        x: A data frame of predictors.\n",
        "        y: A binary response (numeric) vector.\n",
        "        t: A binary response (numeric) representing the treatment assignment\n",
        "            (coded as 0/1).\n",
        "        method: A sklearn model specifying which classification or regression\n",
        "            model to use. This should be a method that can handle a\n",
        "            multinominal class variable.\n",
        "    Return:\n",
        "        Dictionary: A dictionary of two models. One for the treatment group,\n",
        "            one for the control group.\n",
        "            {\n",
        "                'model_treat': a model for the treatment group,\n",
        "                'model_control': a model for the control group\n",
        "            }\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'model_treat': method(**kwargs).fit(x[t == 1], y[t == 1]),\n",
        "        'model_control': method(**kwargs).fit(x[t == 0], y[t == 0])\n",
        "    }\n",
        "\n",
        "\n",
        "def predict_tma(obj, newdata, **kwargs):\n",
        "    \"\"\"Predictions according to the \"Two Model Approach\"\n",
        "    (a.k.a. \"Separate Model Approach\")\n",
        "    For each instance in newdata two predictions are made:\n",
        "    1) What is the probability of a person responding when treated?\n",
        "    2) What is the probability of a person responding when not treated\n",
        "      (i.e. part of control group)?\n",
        "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
        "    Args:\n",
        "        obj: A dictionary of two models.\n",
        "            One for the treatment group, one for the control group.\n",
        "        newdata: A data frame containing the values at which predictions\n",
        "            are required.\n",
        "    Return:\n",
        "        DataFrame: A data frame with predicted returns for when the customers\n",
        "            are treated and for when they are not treated.\n",
        "            'pr_y1_t1': when treated, 'pr_y1_t0': when not treated\n",
        "    \"\"\"\n",
        "    # LogisticRegression: use predict_proba and return result[:, 1] for True class\n",
        "    # LinearRegression: use predict\n",
        "    if isinstance(obj['model_treat'], LogisticRegression):\n",
        "        return pd.DataFrame(data={\n",
        "            'pr_y1_t1': obj['model_treat'].predict_proba(newdata)[:, 1],\n",
        "            'pr_y1_t0': obj['model_control'].predict_proba(newdata)[:, 1]\n",
        "        })\n",
        "    else:\n",
        "        return pd.DataFrame(data={\n",
        "            'pr_y1_t1': obj['model_treat'].predict(newdata),\n",
        "            'pr_y1_t0': obj['model_control'].predict(newdata)\n",
        "        })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShFJ1sROyp8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class Node(object):\n",
        "    \"\"\"\n",
        "    Node of decision tree\n",
        "    \"\"\"\n",
        "    def __init__(self, attribute, threshold):\n",
        "        self.attr = attribute\n",
        "        self.thres = threshold\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.leaf = False\n",
        "        self.predict = None\n",
        "\n",
        "\n",
        "def num_class(df, predict_attr):\n",
        "    \"\"\"\n",
        "    Returns the number of positive and negative data\n",
        "    \"\"\"\n",
        "    return df[df[predict_attr] == 1].shape[0], df[df[predict_attr] == 0].shape[0]\n",
        "\n",
        "\n",
        "def info_entropy(df, predict_attr):\n",
        "    \"\"\"\n",
        "    Calculate info content (entropy) of the test data\n",
        "    \"\"\"\n",
        "    # Data frame and number of positive/negatives examples in the data\n",
        "    p = float(df[df[predict_attr] == 1].shape[0])\n",
        "    n = float(df[df[predict_attr] == 0].shape[0])\n",
        "\n",
        "    # Calculate entropy\n",
        "    if p == 0 or n == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return -(p / (p + n)) * math.log(p / (p + n), 2) - (n / (p + n)) * math.log(n / (p + n), 2)\n",
        "\n",
        "\n",
        "def info_gain(df, attribute, predict_attr):\n",
        "    \"\"\"\n",
        "    Select the information gain and threshold of the attribute to split\n",
        "    The threshold chosen splits the test data such that information gain is maximized\n",
        "    \n",
        "    Return a pandas.DataFrame\n",
        "        columns: 'thres' (threshold) and 'info_gain' (information gain)\n",
        "    \"\"\"\n",
        "    num_total = df.shape[0]\n",
        "    tmp = pd.DataFrame({\n",
        "        'thres': df[attribute],\n",
        "        'Y': df[predict_attr]\n",
        "    })\n",
        "    tmp.sort_values(['thres'], inplace=True)\n",
        "\n",
        "    # Left child node has the observations whose attributes are less than (or equual to) the threshold\n",
        "    # Right child has has the observations whose attributes are greater than the threshold\n",
        "    #   n_pos_L: The number of the positive (y=1) observations in the left child\n",
        "    #   n_neg_L: The number of the negative (y=0) observations in the left child\n",
        "    #   n_L: The number observations in the left child\n",
        "    #   r_pos_L: The average return of the observations in the left child\n",
        "    #   r_pos_R: The average return of the observations in the right child\n",
        "    y_total = sum(df[predict_attr])\n",
        "    tmp['n_pos_L'] = tmp['Y'].cumsum()\n",
        "    tmp['n_neg_L'] = (tmp['Y'] == 0).cumsum()\n",
        "    tmp['n_L'] = tmp['n_pos_L'] + tmp['n_neg_L']\n",
        "    tmp['r_pos_L'] = tmp['n_pos_L']/(tmp['n_L'])\n",
        "    tmp['r_pos_R'] = (y_total - tmp['n_pos_L'])/(num_total - tmp['n_L'])\n",
        "\n",
        "    # H_L: entropy of left child \n",
        "    tmp['H_L'] = -tmp['r_pos_L']*np.log2(tmp['r_pos_L']) - (1 - tmp['r_pos_L']) * np.log2(1 - tmp['r_pos_L'])\n",
        "    \n",
        "    # H_R: entropy of right child\n",
        "    tmp['H_R'] = -tmp['r_pos_R']*np.log2(tmp['r_pos_R']) - (1 - tmp['r_pos_R']) * np.log2(1 - tmp['r_pos_R'])\n",
        "    \n",
        "    # EH: Expected entropy\n",
        "    tmp['EH'] = (tmp['n_L'] * tmp['H_L'] + (num_total - tmp['n_L']) * tmp['H_R']) / num_total\n",
        "\n",
        "    # We will select one rows per one distinct candidate\n",
        "    dups = tmp['thres'].duplicated(keep='last')\n",
        "    tmp['thres_ok'] = (dups == False)\n",
        "    tmp.dropna(inplace=True)\n",
        "    if sum(tmp['thres_ok']) < 1:\n",
        "        return None\n",
        "\n",
        "    tmp = tmp[tmp['thres_ok']]\n",
        "    tmp['info_gain'] = info_entropy(df, predict_attr) - tmp['EH']\n",
        "    \n",
        "    return tmp[['thres', 'info_gain']]\n",
        "\n",
        "\n",
        "def choose_attr(df, attributes, predict_attr):\n",
        "    \"\"\"\n",
        "    Chooses the attribute and its threshold with the highest info gain\n",
        "    from the set of attributes\n",
        "    \"\"\"\n",
        "    max_info_gain = 0\n",
        "    best_attr = None\n",
        "    threshold = None\n",
        "\n",
        "    # Test each attribute (note attributes maybe be chosen more than once)\n",
        "    for attr in attributes:\n",
        "        df_ig = info_gain(df, attr, predict_attr)\n",
        "        if df_ig is None:\n",
        "            continue\n",
        "\n",
        "        # Get the possible indices of maximum info gain\n",
        "        ig = max(df_ig['info_gain'])\n",
        "        idx_ig = df_ig.index[df_ig['info_gain']==ig]\n",
        "        \n",
        "        # Break ties randomly\n",
        "        idx_ig = random.choice(idx_ig)\n",
        "        \n",
        "        # Get information gain & threshold of that\n",
        "        thres = df_ig['thres'][idx_ig]\n",
        "\n",
        "        if ig > max_info_gain:\n",
        "            max_info_gain = ig\n",
        "            best_attr = attr\n",
        "            threshold = thres\n",
        "\n",
        "    return best_attr, threshold\n",
        "\n",
        "\n",
        "def build_tree(df, cols, predict_attr):\n",
        "    \"\"\"\n",
        "    Builds the Decision Tree based on training data, attributes to train on,\n",
        "    and a prediction attribute\n",
        "    \"\"\"\n",
        "    # Get the number of positive and negative examples in the training data\n",
        "    p, n = num_class(df, predict_attr)\n",
        "    \n",
        "    # If train data has all positive or all negative values, or the number of\n",
        "    # the train data is less than the given minimum number of split, then we\n",
        "    # have reached the end of our tree\n",
        "    if p > 0 and n > 0 and (p + n) >= 10000:\n",
        "        # Determine attribute and its threshold value with the highest information gain\n",
        "        best_attr, threshold = choose_attr(df, cols, predict_attr)\n",
        "        \n",
        "        if best_attr is None:\n",
        "            # Create a leaf node indicating it's prediction\n",
        "            leaf = Node(None, None)\n",
        "            leaf.leaf = True\n",
        "            leaf.predict = p / (p + n)\n",
        "            return leaf\n",
        "        \n",
        "        # Create internal tree node based on attribute and it's threshold\n",
        "        sub_1 = df[df[best_attr] <= threshold]\n",
        "        sub_2 = df[df[best_attr] > threshold]\n",
        "        \n",
        "        if sub_1.shape[0] > 0 and sub_2.shape[0] > 0:\n",
        "            tree = Node(best_attr, threshold)\n",
        "            \n",
        "            # Recursively build left and right subtree\n",
        "            tree.left = build_tree(sub_1, cols, predict_attr)\n",
        "            tree.right = build_tree(sub_2, cols, predict_attr)\n",
        "            return tree\n",
        "\n",
        "    # Create a leaf node indicating it's prediction\n",
        "    leaf = Node(None,None)\n",
        "    leaf.leaf = True\n",
        "    leaf.predict = p / (p+n)\n",
        "    return leaf\n",
        "\n",
        "\n",
        "def predict(node, row_df):\n",
        "    \"\"\"\n",
        "    Given a instance of a training data, make a prediction of an observation (row)\n",
        "    based on the Decision Tree\n",
        "    Assumes all data has been cleaned (i.e. no NULL data)\n",
        "    \"\"\"\n",
        "    # If we are at a leaf node, return the prediction of the leaf node\n",
        "    if node.leaf:\n",
        "        return node.predict\n",
        "\n",
        "    # Traverse left or right subtree based on instance's data\n",
        "    if row_df[node.attr] <= node.thres:\n",
        "        return predict(node.left, row_df)\n",
        "    elif row_df[node.attr] > node.thres:\n",
        "        return predict(node.right, row_df)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def test_predictions(root, df, target_attr='y'):\n",
        "    \"\"\"\n",
        "    Given a set of data, make a prediction for each instance using the Decision Tree\n",
        "    \"\"\"\n",
        "    prediction = []\n",
        "    for index, row in df.iterrows():\n",
        "        prediction.append(predict(root, row))\n",
        "\n",
        "    pred_df = pd.Series(prediction)\n",
        "    return pred_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvmhJaMTfGmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uplift_tree_tma(x, y, t, **kwargs):    \n",
        "    df = x.copy()\n",
        "    df['Y'] = y\n",
        "    df['T'] = t\n",
        "    \n",
        "    features = [feat for feat in x.columns]\n",
        "    model_treat = build_tree(df[t==1], features, predict_attr='Y')\n",
        "    model_control = build_tree(df[t==0], features, predict_attr='Y')\n",
        "    \n",
        "    res = {\n",
        "        'model_treat': model_treat,\n",
        "        'model_control': model_control,\n",
        "    }\n",
        "    return res\n",
        "\n",
        "\n",
        "def predict_tree_tma(obj, newdata, **kwargs):\n",
        "    pred_treat = test_predictions(obj['model_treat'], newdata, **kwargs)\n",
        "    pred_control = test_predictions(obj['model_control'], newdata, **kwargs)\n",
        "    \n",
        "    pred_df = pd.DataFrame({\n",
        "        \"pr_y1_t1\": pred_treat,\n",
        "        \"pr_y1_t0\": pred_control,\n",
        "    })\n",
        "    return pred_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4pTS0R7uGmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_uplift(df):\n",
        "    n_t1 = df['T'].sum()\n",
        "    n_t0 = df['T'].count() - n_t1\n",
        "    n_y1_t1 = df[df['T'] == 1]['Y'].sum()\n",
        "    n_y1_t0 = df[df['T'] == 0]['Y'].sum()\n",
        "    return n_y1_t1 / n_t1 - n_y1_t0 / n_t0\n",
        "\n",
        "\n",
        "def get_delta_delta_p(df, attribute, predict_attr):\n",
        "    \"\"\"\n",
        "    Select the information gain and threshold of the attribute to split\n",
        "    The threshold chosen splits the test data such that delta delta p is maximized\n",
        "    \n",
        "    Return a pandas.DataFrame\n",
        "        columns: 'thres' (threshold) and 'info_gain' (delta delta p)\n",
        "    \"\"\"\n",
        "    num_total = df.shape[0]\n",
        "    tmp = pd.DataFrame({\n",
        "        'thres': df[attribute],\n",
        "        'Y': df[predict_attr]\n",
        "    })\n",
        "    tmp.sort_values(['thres'], inplace=True)\n",
        "    \n",
        "    s_thres = tmp['thres'].drop_duplicates()\n",
        "    n_thres = len(s_thres)\n",
        "    if n_thres <= 1:\n",
        "        return None\n",
        "    \n",
        "    s_uplift_left = s_thres.apply(lambda x: calc_uplift(df[df[attribute] <= x])).rename(s_thres)\n",
        "    s_uplift_right = s_thres.apply(lambda x: calc_uplift(df[df[attribute] > x])).rename(s_thres)\n",
        "    \n",
        "    # H_L: uplift of left child \n",
        "    tmp['H_L'] = tmp['thres'].apply(lambda x: s_uplift_left[x])\n",
        "    \n",
        "    # H_R: uplift of right child\n",
        "    tmp['H_R'] = tmp['thres'].apply(lambda x: s_uplift_right[x])\n",
        "    \n",
        "    # We will select one rows per one distinct candidate\n",
        "    dups = tmp['thres'].duplicated(keep='last')\n",
        "    tmp['thres_ok'] = (dups == False)\n",
        "    tmp.dropna(inplace=True)\n",
        "    if sum(tmp['thres_ok']) < 1:\n",
        "        return None\n",
        "    tmp = tmp[tmp['thres_ok']]\n",
        "    \n",
        "    # Calculate delta delta P\n",
        "    tmp['ddp'] = (tmp['H_R'] - tmp['H_L']).abs()\n",
        "\n",
        "    return tmp[['thres', 'ddp']]\n",
        "\n",
        "\n",
        "def choose_delta_delta_p_attr(df, attributes, predict_attr):\n",
        "    \"\"\"\n",
        "    Chooses the attribute and its threshold with the highest delta delta P from the set of attributes\n",
        "    \"\"\"\n",
        "    max_ddp = 0\n",
        "    best_attr = None\n",
        "    threshold = None\n",
        "\n",
        "    # Test each attribute (note attributes maybe be chosen more than once)\n",
        "    for attr in attributes:\n",
        "        df_ddp = get_delta_delta_p(df, attr, predict_attr)\n",
        "        if df_ddp is None:\n",
        "            continue\n",
        "        \n",
        "        # Get the possible indices of maximum delta delta p\n",
        "        ddp = max(df_ddp['ddp'])\n",
        "        idx_ddp = df_ddp.index[df_ddp['ddp'] == ddp]\n",
        "        \n",
        "        # Break ties randomly\n",
        "        idx_ddp = random.choice(idx_ddp)\n",
        "        \n",
        "        # Get information gain & threshold of that\n",
        "        thres = df_ddp['thres'][idx_ddp]\n",
        "\n",
        "        if ddp > max_ddp:\n",
        "            max_ddp = ddp\n",
        "            best_attr = attr\n",
        "            threshold = thres\n",
        "\n",
        "    return best_attr, threshold\n",
        "\n",
        "\n",
        "def build_delta_delta_p_tree(df, cols, predict_attr):\n",
        "    \"\"\"\n",
        "    Builds the Decision Tree based on training data, attributes to train on,\n",
        "    and a prediction attribute\n",
        "    \"\"\"\n",
        "    # Get the number of positive and negative examples in the training data\n",
        "    p, n = num_class(df, predict_attr)\n",
        "    \n",
        "    # If train data has all positive or all negative values, or the number of\n",
        "    # the train data is less than the given minimum number of split, then we\n",
        "    # have reached the end of our tree\n",
        "    if p > 0 and n > 0 and (p + n) >= 10000:\n",
        "        # Determine attribute and its threshold value with the highest information gain\n",
        "        best_attr, threshold = choose_delta_delta_p_attr(df, cols, predict_attr)\n",
        "        \n",
        "        if best_attr is None:\n",
        "            # Create a leaf node indicating it's prediction\n",
        "            leaf = Node(None, None)\n",
        "            leaf.leaf = True\n",
        "            leaf.predict = calc_uplift(df)\n",
        "            return leaf\n",
        "        \n",
        "        # Create internal tree node based on attribute and it's threshold\n",
        "        sub_1 = df[df[best_attr] <= threshold]\n",
        "        sub_2 = df[df[best_attr] > threshold]\n",
        "        \n",
        "        if sub_1.shape[0] > 0 and sub_2.shape[0] > 0:\n",
        "            tree = Node(best_attr, threshold)\n",
        "            \n",
        "            # Recursively build left and right subtree\n",
        "            tree.left = build_delta_delta_p_tree(sub_1, cols, predict_attr)\n",
        "            tree.right = build_delta_delta_p_tree(sub_2, cols, predict_attr)\n",
        "            return tree\n",
        "\n",
        "    # Create a leaf node indicating it's prediction\n",
        "    leaf = Node(None, None)\n",
        "    leaf.leaf = True\n",
        "    leaf.predict = calc_uplift(df)\n",
        "    return leaf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2CIW5KADpV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class Node(object):\n",
        "    def __init__(self, attribute, threshold):\n",
        "        self.attr = attribute\n",
        "        self.thres = threshold\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.leaf = False\n",
        "        self.predict = None, None\n",
        "\n",
        "\n",
        "def info_gain(df, attribute, predict_attr, treatment_attr):\n",
        "    \"\"\"\n",
        "    Select the information gain and threshold of the attribute to split\n",
        "    The threshold chosen splits the test data such that information gain is maximized\n",
        "    \n",
        "    CHANGE:\n",
        "        Information gain is chagned \"\\Delta \\Delta P\" which means the\n",
        "        difference between the uplifts of the treatment and control group\n",
        "    \n",
        "    Return a pandas.DataFrame\n",
        "        columns: 'thres' (threshold) and 'info_gain' (information gain)\n",
        "    \"\"\"\n",
        "    num_total = df.shape[0]\n",
        "    tmp = pd.DataFrame({\n",
        "        'thres': df[attribute],\n",
        "        'Y': df[predict_attr],\n",
        "        'T': df[treatment_attr]\n",
        "    })\n",
        "    tmp.sort_values(['thres'], inplace=True)\n",
        "\n",
        "    tmp['n_t1_L'] = (tmp['T']).cumsum()\n",
        "    tmp['n_t0_L'] = (tmp['T'] == 0).cumsum()\n",
        "    tmp['n_t1_R'] = sum(tmp['T']) - (tmp['T']).cumsum()\n",
        "    tmp['n_t0_R'] = sum(tmp['T'] == 0) - (tmp['T'] == 0).cumsum()\n",
        "    tmp['n_y_t1_L'] = (tmp['T'] & tmp['Y']).cumsum()\n",
        "    tmp['n_y_t0_L'] = ((tmp['T'] == 0) & tmp['Y']).cumsum()\n",
        "    tmp['n_y_t1_R'] = sum(tmp['T'] & tmp['Y']) - (tmp['T'] & tmp['Y']).cumsum()\n",
        "    tmp['n_y_t0_R'] = sum((tmp['T'] == 0) & tmp['Y']) - ((tmp['T'] == 0) & tmp['Y']).cumsum()\n",
        "    \n",
        "    tmp['info_gain'] = ((tmp['n_y_t1_L']/tmp['n_t1_L']) - (tmp['n_y_t0_L']/tmp['n_t0_L'])) \\\n",
        "                     - ((tmp['n_y_t1_R']/tmp['n_t1_R']) - (tmp['n_y_t0_R']/tmp['n_t0_R']))\n",
        "\n",
        "    # We will select one rows per one distinct candidate\n",
        "    tmp['dups'] = tmp['thres'].duplicated(keep='last')\n",
        "    tmp['thres_ok'] = (tmp['dups'] == False)\n",
        "    tmp.dropna(inplace=True)\n",
        "    if sum(tmp['thres_ok']) < 1:\n",
        "        return None\n",
        "\n",
        "    tmp = tmp[tmp['thres_ok']]\n",
        "    \n",
        "    return tmp[['thres', 'info_gain']]\n",
        "    \n",
        "\n",
        "\n",
        "def num_class(df, predict_attr, treatment_attr):\n",
        "    \"\"\"\n",
        "    Returns the number of Responders and Non-responders in Treatment and Control group\n",
        "    \"\"\"\n",
        "    tr = df[(df[predict_attr] == 1) & (df[treatment_attr] == 1)]  # Responders in Treatment group\n",
        "    tn = df[(df[predict_attr] == 0) & (df[treatment_attr] == 1)]  # Non-responders in Treatment group\n",
        "    cr = df[(df[predict_attr] == 1) & (df[treatment_attr] == 0)]  # Responders in Control group\n",
        "    cn = df[(df[predict_attr] == 0) & (df[treatment_attr] == 0)]  # Non-responders in Control group\n",
        "    return tr.shape[0], tn.shape[0], cr.shape[0], cn.shape[0]\n",
        "\n",
        "\n",
        "def choose_attr(df, attributes, predict_attr, treatment_attr):\n",
        "    \"\"\"\n",
        "    Chooses the attribute and its threshold with the highest info gain\n",
        "    from the set of attributes\n",
        "    \"\"\"\n",
        "    max_info_gain = 0\n",
        "    best_attr = None\n",
        "    threshold = None\n",
        "    # Test each attribute (note attributes maybe be chosen more than once)\n",
        "    for attr in attributes:\n",
        "        df_ig = info_gain(df, attr, predict_attr, treatment_attr)\n",
        "        if df_ig is None:\n",
        "            continue\n",
        "\n",
        "        # Get the possible indices of maximum info gain\n",
        "        ig = max(df_ig['info_gain'])\n",
        "        idx_ig = df_ig.index[df_ig['info_gain']==ig]\n",
        "        # Break ties randomly\n",
        "        idx_ig = random.choice(idx_ig)\n",
        "        # Get information gain & threshold of that\n",
        "        thres = df_ig['thres'][idx_ig]\n",
        "\n",
        "        if ig > max_info_gain:\n",
        "            max_info_gain = ig\n",
        "            best_attr = attr\n",
        "            threshold = thres\n",
        "    return best_attr, threshold\n",
        "\n",
        "\n",
        "\n",
        "def build_tree(df, cols, predict_attr='Y', treatment_attr='T', depth=0,\n",
        "               min_split=200, max_depth=10, min_bucket_t1=50, min_bucket_t0=50):\n",
        "    \"\"\"\n",
        "    Builds the Decision Tree based on training data, attributes to train on,\n",
        "    and a prediction attribute\n",
        "    \"\"\"\n",
        "    # Get the number of positive and negative examples in the training data\n",
        "    total_num = df.shape[0]\n",
        "    tr, tn, cr, cn = num_class(df, predict_attr, treatment_attr)\n",
        "    # Whether we have to split this node\n",
        "    split_cond = (tr + tn > min_split and cr + cn > min_split) #\\\n",
        "        #and (depth <= max_depth) \\\n",
        "        #and (tr + tn > min_bucket_t1 and cr + cn > min_bucket_t0)\n",
        "\n",
        "    best_attr, threshold = None, None\n",
        "    if split_cond:\n",
        "        # Determine attribute and its threshold value with the highest\n",
        "        # information gain\n",
        "        best_attr, threshold = choose_attr(df, cols, predict_attr, treatment_attr)\n",
        "    \n",
        "    if best_attr is None:\n",
        "        # Create a leaf node indicating it's prediction\n",
        "        leaf = Node(None,None)\n",
        "        leaf.leaf = True\n",
        "        leaf.predict = (tr / (tr + tn), cr / (cr + cn))\n",
        "        return leaf\n",
        "    else:\n",
        "        # Create internal tree node based on attribute and it's threshold\n",
        "        sub_1 = df[df[best_attr] <= threshold]\n",
        "        sub_2 = df[df[best_attr] > threshold]\n",
        "        sub1_tr, sub1_tn, sub1_cr, sub1_cn = num_class(sub_1, predict_attr, treatment_attr)\n",
        "        sub2_tr, sub2_tn, sub2_cr, sub2_cn = num_class(sub_2, predict_attr, treatment_attr)\n",
        "        if sub1_tr + sub1_tn < 1 or sub1_cr + sub1_cn < 1 \\\n",
        "                or sub2_tr + sub2_tn < 1 or sub2_cr + sub2_cn < 1:\n",
        "            # Create a leaf node indicating it's prediction\n",
        "            leaf = Node(None,None)\n",
        "            leaf.leaf = True\n",
        "            leaf.predict = (tr / (tr + tn), cr / (cr + cn))\n",
        "            return leaf\n",
        "        tree = Node(best_attr, threshold)\n",
        "        # Recursively build left and right subtree\n",
        "        tree.left = build_tree(sub_1, cols, predict_attr, treatment_attr, depth + 1,\n",
        "                               min_split, max_depth, min_bucket_t1, min_bucket_t0)\n",
        "        tree.right = build_tree(sub_2, cols, predict_attr, treatment_attr, depth + 1,\n",
        "                                min_split, max_depth, min_bucket_t1, min_bucket_t0)\n",
        "        return tree\n",
        "\n",
        "\n",
        "def predict(node, row_df):\n",
        "    \"\"\"\n",
        "    Given a instance of a training data, make a prediction of an observation (row)\n",
        "    based on the Decision Tree\n",
        "    Assumes all data has been cleaned (i.e. no NULL data)\n",
        "    \"\"\"\n",
        "    # If we are at a leaf node, return the prediction of the leaf node\n",
        "    if node.leaf:\n",
        "        return node.predict\n",
        "    # Traverse left or right subtree based on instance's data\n",
        "    if row_df[node.attr] <= node.thres:\n",
        "        return predict(node.left, row_df)\n",
        "    elif row_df[node.attr] > node.thres:\n",
        "        return predict(node.right, row_df)\n",
        "\n",
        "\n",
        "def test_predictions(root, df):\n",
        "    \"\"\"\n",
        "    Given a set of data, make a prediction for each instance using the Decision Tree\n",
        "    \"\"\"\n",
        "    pred_treat = []\n",
        "    pred_control = []\n",
        "    for index,row in df.iterrows():\n",
        "        return_treated, return_control = predict(root, row)\n",
        "        pred_treat.append(return_treated)\n",
        "        pred_control.append(return_control)\n",
        "    pred_df = pd.DataFrame({\n",
        "        \"pr_y1_t1\": pred_treat,\n",
        "        \"pr_y1_t0\": pred_control,\n",
        "    })\n",
        "    return pred_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-nY5d-EDjUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uplift_tree(x, y, t, **kwargs):\n",
        "    df = x.copy()\n",
        "    df['Y'] = y\n",
        "    df['T'] = t\n",
        "    \n",
        "    root = build_tree(df, x.columns, predict_attr='Y', treatment_attr='T', min_split=2000)#,\n",
        "                      #depth=0, min_split=2000, max_depth=3, min_bucket_t1=1000, min_bucket_t0=1000)\n",
        "    \n",
        "    return root\n",
        "\n",
        "\n",
        "predict_tree = test_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hREl_CRv9DYC",
        "outputId": "6bb83890-90d4-4b5c-ddc8-927fae744188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "\n",
        "\n",
        "def ty_assign(y, t):\n",
        "    if y == 1 and t == 1:\n",
        "        return \"TR\"\n",
        "    elif y == 0 and t == 1:\n",
        "        return \"TN\"\n",
        "    elif y == 1 and t == 0:\n",
        "        return \"CR\"\n",
        "    elif y == 0 and t == 0:\n",
        "        return \"CN\"\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "    \n",
        "def main():\n",
        "    ### Hyper parameters ###\n",
        "    dataset = 'hillstrom'\n",
        "    seed = 1234\n",
        "    n_fold = 5\n",
        "    models = {\n",
        "        'tma': {'model': tma, 'predict': predict_tma}\n",
        "    }\n",
        "    search_space = {\n",
        "        'method': [LogisticRegression],\n",
        "        'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
        "        'penalty': ['none', 'l2'],\n",
        "        'tol': [1e-2, 1e-3, 1e-4],\n",
        "        'C': [1e6, 1e3, 1, 1e-3, 1e-6]\n",
        "    }\n",
        "    param_tuning = False\n",
        "\n",
        "    # Preprocessing data & K fold validation\n",
        "    if dataset == 'hillstrom':\n",
        "        df_all = preprocess_data(hillstrom_df, dataset)\n",
        "        #fold_split = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed).split(\n",
        "        #    df_all.drop(columns=['T', 'Y']), df_all[['T','Y']].apply(lambda row: ty_assign(row['Y'], row['T']), axis=1))\n",
        "        fold_split = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed).split(\n",
        "            df_all, df_all['T'] * 2 + df_all['Y'])\n",
        "    elif dataset == 'lalonde':\n",
        "        df_all = preprocess_data(lalonde_df, dataset)\n",
        "        fold_split = KFold(n_splits=n_fold, shuffle=True, random_state=seed).split(df_all)\n",
        "    else:\n",
        "        assert ()\n",
        "\n",
        "    for model_name in models:\n",
        "        qini_list = []\n",
        "        best_params = {}\n",
        "\n",
        "        for train_index, test_index in fold_split:\n",
        "            if param_tuning:\n",
        "                df_train = df_all.reindex(train_index).reset_index(drop=True)\n",
        "                df_test = df_all.reindex(test_index).reset_index(drop=True)\n",
        "\n",
        "                # Data split: 2/3 tuning dataset, 1/3 validation dataset\n",
        "                stratify = pd.DataFrame([df_train['Y'], df_train['T']]).T\n",
        "                df_tune, df_val = train_test_split(df_train, test_size=0.33, random_state=seed, stratify=stratify)\n",
        "\n",
        "                # Variable selection (General wrapper approach)\n",
        "                data_dict = {\n",
        "                    \"x_train\": df_tune.drop(columns=['Y', 'T']).reset_index(drop=True),\n",
        "                    \"y_train\": df_tune['Y'].reset_index(drop=True),\n",
        "                    \"t_train\": df_tune['T'].reset_index(drop=True),\n",
        "                    \"x_test\": df_val.drop(columns=['Y', 'T']).reset_index(drop=True),\n",
        "                    \"y_test\": df_val['Y'].reset_index(drop=True),\n",
        "                    \"t_test\": df_val['T'].reset_index(drop=True),\n",
        "                }\n",
        "\n",
        "                model_method = search_space.get('method', None)\n",
        "                params = {\n",
        "                    'method': None if model_method is None else model_method[0],\n",
        "                }\n",
        "                if params['method'] == LogisticRegression:\n",
        "                    solver = search_space.get('solver', None)\n",
        "                    params['solver'] = None if solver is None else solver[0]\n",
        "\n",
        "                _, drop_vars, qini_values = wrapper(models[model_name]['model'],  models[model_name]['predict'],\n",
        "                                                    data_dict, params=params)\n",
        "\n",
        "                best_qini = max(qini_values)\n",
        "                best_idx = qini_values.index(best_qini)\n",
        "                best_drop_vars = drop_vars[: best_idx]\n",
        "\n",
        "                data_dict['x_train'].drop(best_drop_vars, axis=1, inplace=True)\n",
        "                data_dict['x_test'].drop(best_drop_vars, axis=1, inplace=True)\n",
        "                df_train.drop(best_drop_vars, axis=1, inplace=True)\n",
        "                df_test.drop(best_drop_vars, axis=1, inplace=True)\n",
        "\n",
        "                # Parameter tuning\n",
        "                _, best_params = parameter_tuning(models[model_name]['model'], models[model_name]['predict'],\n",
        "                                                  data_dict, search_space=search_space)\n",
        "            else:\n",
        "                if model_name == 'tma':\n",
        "                    best_params = {\n",
        "                        'method': LogisticRegression,\n",
        "                        'solver': 'newton-cg',\n",
        "                        'C': 1e8\n",
        "                    }\n",
        "\n",
        "            # Train model and predict\n",
        "            x_train = df_all.drop(columns=['T', 'Y']).reindex(train_index).reset_index(drop=True)\n",
        "            y_train = df_all['Y'].reindex(train_index).reset_index(drop=True)\n",
        "            t_train = df_all['T'].reindex(train_index).reset_index(drop=True)\n",
        "\n",
        "            x_test = df_all.drop(columns=['T', 'Y']).reindex(test_index).reset_index(drop=True)\n",
        "            y_test = df_all['Y'].reindex(test_index).reset_index(drop=True)\n",
        "            t_test = df_all['T'].reindex(test_index).reset_index(drop=True)\n",
        "\n",
        "            model = models[model_name]['model'](x_train, y_train, t_train, **best_params)\n",
        "            pred = models[model_name]['predict'](model, x_test)\n",
        "            print(pred[:5])\n",
        "\n",
        "            # Calculate qini value\n",
        "            perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], y_test, t_test)\n",
        "            print(perf[:5])\n",
        "            q = qini(perf)\n",
        "            qini_list.append(q['qini'])\n",
        "\n",
        "        print(\"Model: {}\\n\".format(model_name))\n",
        "        print(\"Tuning space: \\n\")\n",
        "        for key, val in search_space.items():\n",
        "            print(\"    '{}': {}\\n\".format(key, val))\n",
        "        print(\"Seed: {}\\n\".format(seed))\n",
        "        print('Qini values: ', qini_list)\n",
        "        print(\"Qini value: mean = {}, std = {}\\n\\n\".format(np.mean(qini_list), np.std(qini_list)))\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   pr_y1_t1  pr_y1_t0\n",
            "0  0.128176  0.053017\n",
            "1  0.063542  0.041249\n",
            "2  0.146681  0.141535\n",
            "3  0.242022  0.158832\n",
            "4  0.094111  0.077650\n",
            "       n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0  n_t1  n_t0    uplift\n",
            "group                                                            \n",
            "1           71       60  0.169856  0.137615   418   436  0.032242\n",
            "2           91       41  0.216152  0.094688   421   433  0.121464\n",
            "3           81       46  0.190141  0.107477   426   428  0.082664\n",
            "4           76       43  0.175520  0.102138   433   421  0.073382\n",
            "5           67       34  0.160287  0.077982   418   436  0.082305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   pr_y1_t1  pr_y1_t0\n",
            "0  0.243593  0.179598\n",
            "1  0.157560  0.155070\n",
            "2  0.163740  0.099698\n",
            "3  0.100295  0.034678\n",
            "4  0.145243  0.065182\n",
            "       n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0  n_t1  n_t0    uplift\n",
            "group                                                            \n",
            "1           84       58  0.207921  0.128889   404   450  0.079032\n",
            "2           91       45  0.209195  0.107399   435   419  0.101797\n",
            "3           76       37  0.177156  0.087059   429   425  0.090097\n",
            "4           66       40  0.152778  0.094787   432   422  0.057991\n",
            "5           72       31  0.159292  0.077114   452   402  0.082178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   pr_y1_t1  pr_y1_t0\n",
            "0  0.154636  0.070087\n",
            "1  0.202492  0.132765\n",
            "2  0.198584  0.227283\n",
            "3  0.241463  0.166460\n",
            "4  0.165761  0.100741\n",
            "       n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0  n_t1  n_t0    uplift\n",
            "group                                                            \n",
            "1           89       65  0.219753  0.144766   405   449  0.074987\n",
            "2           73       56  0.169374  0.132388   431   423  0.036986\n",
            "3           71       43  0.172749  0.097065   411   443  0.075684\n",
            "4           70       33  0.158014  0.080292   443   411  0.077722\n",
            "5           83       23  0.187359  0.055961   443   411  0.131398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCDcioS+EEG5EQl8IIdzI/wM1gMKpDO1S9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   pr_y1_t1  pr_y1_t0\n",
            "0  0.091749  0.069584\n",
            "1  0.132314  0.063997\n",
            "2  0.173086  0.076581\n",
            "3  0.093376  0.075376\n",
            "4  0.196949  0.125696\n",
            "       n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0  n_t1  n_t0    uplift\n",
            "group                                                            \n",
            "1           77       47  0.185096  0.107306   416   438  0.077790\n",
            "2           90       51  0.212766  0.118329   423   431  0.094436\n",
            "3           68       50  0.162679  0.114679   418   436  0.048001\n",
            "4           74       43  0.168565  0.103865   439   414  0.064700\n",
            "5           66       35  0.148315  0.085575   445   409  0.062740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwolI6AshhBOR0BdCCCfyf79wJEAyrkcWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   pr_y1_t1  pr_y1_t0\n",
            "0  0.172319  0.088897\n",
            "1  0.113646  0.042267\n",
            "2  0.136361  0.055810\n",
            "3  0.125747  0.053976\n",
            "4  0.078158  0.054360\n",
            "       n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0  n_t1  n_t0    uplift\n",
            "group                                                            \n",
            "1           92       64  0.216471  0.149184   425   429  0.067286\n",
            "2           78       59  0.177677  0.142169   439   415  0.035508\n",
            "3           80       56  0.193705  0.127273   413   440  0.066432\n",
            "4           81       28  0.173820  0.072165   466   388  0.101655\n",
            "5           63       42  0.154034  0.094595   409   444  0.059440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqEvhBA+REJfCCF8iIS+EEL4kP8HSRPpjPHwM3wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: tma\n",
            "\n",
            "Tuning space: \n",
            "\n",
            "    'method': [<class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
            "\n",
            "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
            "\n",
            "    'penalty': ['none', 'l2']\n",
            "\n",
            "    'tol': [0.01, 0.001, 0.0001]\n",
            "\n",
            "    'C': [1000000.0, 1000.0, 1, 0.001, 1e-06]\n",
            "\n",
            "Seed: 1234\n",
            "\n",
            "Qini values:  [0.008276744288062115, 0.01047067922145626, 0.007280192981595216, 0.0069777384025745195, 0.0048877030793830975]\n",
            "Qini value: mean = 0.007578611594614241, std = 0.0018189301973819715\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZQ4Y1LFfd8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "e33f66a9-ca1a-4086-fa39-5b2cfac61b86"
      },
      "source": [
        "def main_basic_tree():\n",
        "    ### Hyper parameters ###\n",
        "    dataset = 'hillstrom'\n",
        "    seed = 1234\n",
        "    n_fold = 5\n",
        "\n",
        "    # Preprocessing data & K fold validation\n",
        "    if dataset == 'hillstrom':\n",
        "        df_all = preprocess_data(hillstrom_df, dataset)\n",
        "        fold_split = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed).split(\n",
        "            df_all.drop(columns=['T', 'Y']), df_all[['T','Y']].apply(lambda row: ty_assign(row['Y'], row['T']), axis=1))\n",
        "    elif dataset == 'lalonde':\n",
        "        df_all = preprocess_data(lalonde_df, dataset)\n",
        "        fold_split = KFold(n_splits=n_fold, shuffle=True, random_state=seed).split(df_all)\n",
        "    else:\n",
        "        assert()\n",
        "\n",
        "    for train_index, test_index in fold_split:\n",
        "        # Drop history column due to too slow learning speed\n",
        "        df_train = df_all.reindex(train_index).reset_index(drop=True).drop(['history'], axis=1)\n",
        "        df_test = df_all.reindex(test_index).reset_index(drop=True).drop(['history'], axis=1)\n",
        "\n",
        "        y_test = df_all['Y'].reindex(test_index).reset_index(drop=True)\n",
        "        t_test = df_all['T'].reindex(test_index).reset_index(drop=True)\n",
        "\n",
        "        assert ((df_train.columns == df_test.columns).all())\n",
        "\n",
        "        # Build decision tree and predict\n",
        "        attributes = [col for col in df_train.columns if col != 'Y']\n",
        "        #root = build_tree(df_train, attributes, 'Y')\n",
        "        root = build_delta_delta_p_tree(df_train, attributes, 'Y')\n",
        "        pred = test_predictions(root, df_test)\n",
        "        print('pred: {}'.format(pred[: 5]))\n",
        "\n",
        "\n",
        "main_basic_tree()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred: 0    0.070838\n",
            "1    0.017714\n",
            "2    0.005058\n",
            "3    0.070838\n",
            "4    0.005058\n",
            "dtype: float64\n",
            "pred: 0    0.044523\n",
            "1    0.029700\n",
            "2    0.044523\n",
            "3    0.074758\n",
            "4    0.074758\n",
            "dtype: float64\n",
            "pred: 0    0.075799\n",
            "1    0.048359\n",
            "2    0.018660\n",
            "3    0.048359\n",
            "4    0.048359\n",
            "dtype: float64\n",
            "pred: 0    0.005615\n",
            "1    0.050093\n",
            "2    0.121615\n",
            "3    0.005615\n",
            "4    0.050093\n",
            "dtype: float64\n",
            "pred: 0    0.080943\n",
            "1    0.080943\n",
            "2    0.080943\n",
            "3    0.080943\n",
            "4    0.022786\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzSJmTSGQ0ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "aa97eca8-ec6e-43cb-87df-dcab5ae1edea"
      },
      "source": [
        "def main_tree():\n",
        "    ### Hyper parameters ###\n",
        "    dataset = 'hillstrom'\n",
        "    seed = 1234\n",
        "    n_fold = 5\n",
        "    models = {\n",
        "        'tma': {'model': uplift_tree_tma, 'predict': predict_tree_tma}\n",
        "    }\n",
        "\n",
        "    # Preprocessing data & K fold validation\n",
        "    if dataset == 'hillstrom':\n",
        "        df_all = preprocess_data(hillstrom_df, dataset)\n",
        "        fold_split = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed).split(df_all, df_all['Y'])\n",
        "    elif dataset == 'lalonde':\n",
        "        df_all = preprocess_data(lalonde_df, dataset)\n",
        "        fold_split = KFold(n_splits=n_fold, shuffle=True, random_state=seed).split(df_all)\n",
        "    else:\n",
        "        assert ()\n",
        "\n",
        "    for model_name in models:\n",
        "        qini_list = []\n",
        "\n",
        "        for train_index, test_index in fold_split:\n",
        "            # Drop history column due to too slow learning speed\n",
        "            df_train = df_all.reindex(train_index).reset_index(drop=True).drop(['history'], axis=1)\n",
        "            df_test = df_all.reindex(test_index).reset_index(drop=True).drop(['history'], axis=1)\n",
        "\n",
        "            x_train = df_train.drop(columns=['T', 'Y'])\n",
        "            y_train = df_train['Y'].reindex(train_index)\n",
        "            t_train = df_train['T'].reindex(train_index)\n",
        "\n",
        "            x_test = df_test.drop(columns=['T', 'Y'])\n",
        "            y_test = df_test['Y']\n",
        "            t_test = df_test['T']\n",
        "\n",
        "            # Build decision tree and predict on Two Model approach\n",
        "            best_params = {}\n",
        "            model = models[model_name]['model'](x_train, y_train, t_train, **best_params)\n",
        "            pred = models[model_name]['predict'](model, x_test)\n",
        "\n",
        "            # Calculate qini value\n",
        "            perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], y_test, t_test)\n",
        "            q = qini(perf)\n",
        "            qini_list.append(q['qini'])\n",
        "\n",
        "        print(\"Model: {}\\n\".format(model_name))\n",
        "        print(\"Seed: {}\\n\".format(seed))\n",
        "        print('Qini values: ', qini_list)\n",
        "        print(\"Qini value: mean = {}, std = {}\\n\\n\".format(np.mean(qini_list), np.std(qini_list)))\n",
        "\n",
        "\n",
        "main_tree()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-81fc5326b62b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmain_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-81fc5326b62b>\u001b[0m in \u001b[0;36mmain_tree\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     models = {\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;34m'tma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muplift_tree_tma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict_tree_tma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'uplift_tree_tma' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Bv1JVifcNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "812b4a3c-b7d6-4b3e-8be1-803b9cae2136"
      },
      "source": [
        "def main_uplift():\n",
        "    df = pd.read_csv('Hillstrom.csv')\n",
        "    dataset = 'hillstrom'\n",
        "    df = preprocess_data(df)\n",
        "    Y = df['Y']\n",
        "    T = df['T']\n",
        "    X = df.drop(['Y', 'T'], axis=1)\n",
        "    ty = pd.DataFrame({'Y': Y, 'T': T})\\\n",
        "             .apply(lambda row: ty_assign(row['Y'], row['T']), axis=1)\n",
        "    fold_gen = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234).split(X, ty)\n",
        "\n",
        "    ### Cross validation ###\n",
        "    qini_list = []\n",
        "    for idx, (train_index, test_index) in enumerate(fold_gen):\n",
        "        X_train = X.reindex(train_index)\n",
        "        X_test = X.reindex(test_index)\n",
        "        Y_train = Y.reindex(train_index)\n",
        "        Y_test = Y.reindex(test_index)\n",
        "        T_train = T.reindex(train_index)\n",
        "        T_test = T.reindex(test_index)\n",
        "\n",
        "        mdl = uplift_tree(X_train, Y_train, T_train)\n",
        "        pred = predict_tree(mdl, X_test)\n",
        "        print(pred[: 5])\n",
        "        perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], Y_test, T_test)\n",
        "        print(perf[: 5])\n",
        "        q = qini(perf)\n",
        "        qini_list.append(q['qini'])\n",
        "    print('Qini values: ', qini_list)\n",
        "    print('    mean: {}, std: {}'.format(np.mean(qini_list), np.std(qini_list)))\n",
        "\n",
        "\n",
        "main_uplift()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c03cadd6a9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmain_uplift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-c03cadd6a9b2>\u001b[0m in \u001b[0;36mmain_uplift\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain_uplift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hillstrom.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hillstrom'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BBMPlde_-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}